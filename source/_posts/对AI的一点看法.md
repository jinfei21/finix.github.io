---
title: 对AI的一点看法
date: 2018-06-06 11:13:32
tags: [AI]
categories: 技术
author: 费永军
---

## 前言
&emsp;&emsp;任你波涛汹涌，我自静静道来，今天要聊的话题是AI。前段时间百度AI负责人陆奇离职，一度登上头条闹的沸沸扬扬，百度因此市值下降几百亿。AI其实并不算一个新学科，早在二战时期人们就已经开始了人工智能的研究，历史上曾经经历过几次低潮期，直到最近这几年深度学习起来以后，人工智能开始重新火热起来，已经成为资本市场竞相追逐的对象。现在甚至到了人工智能恐怖时代，仿佛马上计算机要取代人类大脑，人类马上要被机器打败甚至统治。我今天要聊的，就是要破除这些迷信，还人工智能一个本来面目。
&emsp;&emsp;我本人研究生期间做的是数据挖掘方向，是人工智能的一个分支，硕士论文做的是有关BP神经网络方面的东西，曾经为了推导公式原理花了一个多月时间才弄明白，当然现在我都还给老师了。目前我也正在学习TensorFlow，了解相关模型原理，学习这个只是为了满足自己的好奇心，工作中其实用不上。交代这个背景，只是为了说明，聊人工智能我是有背景做背书的。


## 正文
&emsp;&emsp;先来看看早期人们对人工智能的定义，最著名的就是图灵测试。图灵测试是二战时期英国科学家图灵首先提出的，指测试者与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）向被测试者随意提问，进行多次测试后，如果有超过30%的测试者不能确定出被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。

&emsp;&emsp;以上是AI鼻祖图灵对人工智能的定义，有发现什么问题吗？第一对测试的问题域没有做限定，就是说智能本身是模仿人，人天生是往专的方向走的，只可能对某些领域比较熟悉，不可能全门类全领域全都熟悉。第二对智能没有等级认定，比如三岁的儿童和12岁的儿童，所对应的智能肯定是不一样的，成年人之间也有可能不一样，因为大家的知识背景不一样。第三对被测试人没有做情绪筛选，很容易测试者通过一些刺激情绪的手段作弊判断出人和机器的区别。第四没有对智能提出进化要求，即智能必需能自我驱动自我学习。

&emsp;&emsp;早期的人工智能研究也确实都是模仿人。比如语音识别，会请语言学家搞很复杂的语法规则模型，不管怎么复杂，对识别率都没有明显提升，相反那些规则多到人都没有办法理解的地步，最后都进行不下去，直接导致了后面的人工智能危机，使得人工智能研究陷入低谷，直到后面基于数据驱动的方法出来，人工智能才重新焕发生机。基于数据驱动的方式之所以我个人觉得达到了智能的基本要求，是因为早期的人工智能都是基于规则的，一旦规则库确定，计算机的智能就确定了，机器没有自我进化学习的能力，本质上计算机不能自主发现知识只能匹配知识。而基于数据驱动的方法，可以随着数据量的丰富，自我进化更新知识库具备了一定的学习能力，计算机会变得越来越智能，甚至能从数据中发现人不能发现的知识。

&emsp;&emsp;基于数据的驱动方法给了计算机自我学习的能力，是不是计算机就真的智能了，甚至到了取代人类的地步呢？计算机获取智能的方式其实和人还是有根本不同的，现在的深度学习基于数据驱动的，说到底还是一个高级数学函数拟合器。也就是先把某一个领域的知识建立模型，选取具有参考意义的特征维度表示成向量，然后通过一系列激活函数的组合，最后通过数据不断的训练，调整组合网络中的权重，最终收敛获得一个坐标系中的曲线或者曲面而已。智能的最优解，就是对应组合网络中权重的最优解。说到底就是一个搜索匹配，比如科学家建立一个模型只能解决一类智能问题，并不能解决所有问题，像google的阿法狗就只能下围棋，不会干别的，虽然下围棋比人类厉害，但是识别语音就做不了，自动驾驶也做不了。

&emsp;&emsp;往深了说，计算机只具备概然性思维，不具有因果思维。人工智能所获取的知识是基于以往的数据所建立的模型，至于预测未来都是在这个逻辑模型（收敛曲线或曲面）基础上的线性延伸。人工智能智能回答what，不能回答why，更不能回答how。而我们人类智能之所以高级，能处理多种智能问题，是因为我们是有因果思维链条，能改进我们的智能。我们能根据历史经验也就是数据，能描述what，然后分析出原因，能回答why，了解清楚原理后，甚至能回答how，告诉怎么做到，这相当于创造性思维，这个目前的人工智能还远不能具备。虽然目前AI在某些方面超过了人类，但是AI并不知道它在干什么。而要让计算机理解它在干什么，必须让计算机学会因果关系，这是一条非常艰难的路，也是一条革命道路。

&emsp;&emsp;目前美国的教授珀尔就在做这个工作，他要让计算机学会因果关系。据他研究，他把因果思维分成三个等级：
1. 第一级思维叫观察，通过数据分析做出预测。
&emsp;&emsp;你的生活经验表明下雨会把衣服淋湿，所以下次下雨你会打伞，这就是观察思维。观察是寻找变量之间的相关性，观察就是积累经验。目前所有实用的AI技术都是基于这个第一级思维。AlphaGo 下围棋，并不是它理解这步棋有什么用，它只不过知道走这步赢棋的概率会更大。
&emsp;&emsp;比如你开个小超市，有卖牙膏和牙刷。观察思维问的问题是，如果一个顾客买牙膏的话，他有多大的概率同时也买牙刷呢？这个知识对你很有用，你可以判断要不要把牙刷和牙膏放一起，它们应该按什么比例进货。

2. 第二级思维叫干预，是预判一个行动的结果。
&emsp;&emsp;干预，是说如果我现在把牙膏的价格给提高一倍，对牙刷的销量会有什么影响？这不是以往的数据所能告诉你的。是，以前可能发生过牙膏价格是现在一倍的情况，但是你不能用以前那个经验预测现在这个行动的结果。因为以前牙膏价格高，是因为别的缘故。可能当时牙膏紧缺才卖得贵。现在我们说的是，不管别人家牙膏卖多少钱，你单方面采取行动，刻意地干预牙膏价格，对牙刷的销量有什么影响。这种事儿从来都没发生过。想知道结果，最好的办法是做实验。互联网公司一直都在做各种“A/B测试”，看看哪个标题能吸引更多点击，什么颜色的网页能让用户停留时间更长，都是用分组测试的方法。测试是主动的干预。其实生活中我们一直都在做干预动作。新电影票房不太好，到底应该花钱做个电视广告呢，还是让明星爆个料？以往的经验可以给你一些提示，但干预动作的结果到底会怎样，你需要更高级的判断。

3. 第三级思维叫想象，是对以前发生的事的反思。
&emsp;&emsp;第三级思维问的问题是，如果我当时是那么做的话，现在会是一个什么样的结果？我现在工资很低，要是我当初好好学数学，现在从事人工智能工作，现在的工资会是多少呢？
&emsp;&emsp;你问的是一个从来没发生过的事情，这叫反事实（counterfactual）分析。如果纳粹德国抢先一步发明原子弹，现在的世界会是什么样的？这件事儿在历史上并有没有发生，你积累的大数据好像用不上。
&emsp;&emsp;很多人爱说一句话，叫“历史不容假设” —— 这句话是错的。正是因为我们会假设，我们能想象不一样的可能性，我们才是高级动物。想象是智人的超能力。珀尔引用了赫拉利在《人类简史》里的说法，大约是在七万年前，智人发生了一起“认知革命” —— 智人开始想象一些不存在的东西。
&emsp;&emsp;你没当过程序员，但是你可以想象，如果你当了程序员，你的生活会是怎样。能想象没有发生的事，就说明你能对以前做的事做出反思。能反思，你就可以想办法改进。正是因为我们会反事实的想象，我们才会为自己的行动负责。

&emsp;&emsp;对照珀尔教授的研究，目前深度学习基于大数据的人工智能，只在第一层次。更严重的问题，目前人工智能仅仅单纯依靠算法去占领市场完全忽略人性，要知道人性往往趋向于低俗，低俗可能难听了点，说好听一点是庸俗，如果不对算法做约束引导会是什么后果？就像今日头条单纯依靠人工智能算法推荐新闻，如果不加干预，完全依照用户点击推荐，推荐的大部分都是三俗恶搞类型，是的，短时期可以获取用户占领市场，这样下去迟早有一天会作死自己。

## 总结
&emsp;&emsp;好了，介绍了珀尔教授的一些研究和我的一些个人观点，相信你对人工智能有了一个新的认识。就目前人工智能用于自动驾驶，应该来说还有很长的路要走，不仅是法律道德层面问题，更是技术上的问题。前面交代过人工智能都是人赋予逻辑模型的线性思维，不能应对经验以外的突发事件。就算珀尔教授说因果关系才是智能关键，如果你佛学背景深一些的话，因果律相当于佛教理论的公设不容质疑，也符合人类的思考习惯。再进一步，你西方哲学背景深一些的话，因果律都是被质疑的，这个世界混乱到你无法想象的地步，因果律是人类把握确定性，应对生存不确定性的救命稻草。我要说的是，人类在对自身没有搞清楚之前，是不可能搞出一个超出人自身的机器取代人类，所以人类还是有希望的，不必过于担心。只不过马上智能时代来临之前，你要转变的是你的生存形态，不然确实容易被时代淘汰，当然这很复杂，是另一个话题。
